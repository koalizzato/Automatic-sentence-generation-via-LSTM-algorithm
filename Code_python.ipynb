{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35128362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from keras.datasets import imdb\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from keras import layers\n",
    "from keras.layers import Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f2e934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b07d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9155feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('File_camaleonti.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01c2eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I camaleonti si nutrono principalmente di inse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alcune specie più grandi possono cacciare picc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La loro lingua appiccicosa e rapida è l'arma p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le prede vengono afferrate con un movimento fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Questi rettili cacciano principalmente durante...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Testo\n",
       "0  I camaleonti si nutrono principalmente di inse...\n",
       "1  Alcune specie più grandi possono cacciare picc...\n",
       "2  La loro lingua appiccicosa e rapida è l'arma p...\n",
       "3  Le prede vengono afferrate con un movimento fu...\n",
       "4  Questi rettili cacciano principalmente durante..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd1d439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c11dc67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12e0550e",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Notiamo che visto che noi vogliamo un algoritmo che sappia parlare, vogliamo tenre un testo più simile all'italiano possibile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2711dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0db62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usiamo le espessioni regolari per eliminari tutti i carattere non alfa-numerici\n",
    "# \\d tiene anche i caratteri numerici\n",
    "data['Testo_Pulito'] = data.Testo.str.lower().str.replace('[^\\w\\s\\d]',' ', regex=True)\n",
    "data['Testo_Pulito'] = data['Testo_Pulito'].str.split()\n",
    "# Leviamo tutte le maiuscole\n",
    "data['Testo'] = data['Testo'].str.lower()\n",
    "data['Testo'] = data.Testo.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "002beb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 30368.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Rimuoviamo le stopwords e ricostruiamo il testo\n",
    "stop = stopwords.words('italian')\n",
    "stop.extend(['good', 'bad', 'dont', 'many', 'excellent', 'would', 'perfect', 'even', 'great','nice', 'amazing'])\n",
    "data['Testo_Pulito'] = data['Testo_Pulito'].progress_apply(lambda x: ' '.join([item for item in x if item not in stop]))\n",
    "data['Testo_Pulito'] = data['Testo_Pulito'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca42bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 700/700 [00:00<00:00, 40481.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.phrases import Phrases\n",
    "\n",
    "# Bigrammi\n",
    "bigram_model = Phrases(data['Testo_Pulito'], min_count=5, threshold=0.3)\n",
    "data['Testo_Pulito'] = data['Testo_Pulito'].progress_apply(lambda x: bigram_model[bigram_model[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4dd0d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testo</th>\n",
       "      <th>Testo_Pulito</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, camaleonti, si, nutrono, principalmente, d...</td>\n",
       "      <td>[camaleonti, nutrono, principalmente, insetti,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[alcune, specie, più, grandi, possono, cacciar...</td>\n",
       "      <td>[alcune_specie, grandi, possono, cacciare, pic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[la, loro, lingua, appiccicosa, e, rapida, è, ...</td>\n",
       "      <td>[lingua_appiccicosa, rapida, arma, principale,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[le, prede, vengono, afferrate, con, un, movim...</td>\n",
       "      <td>[prede, vengono, afferrate, movimento, fulmine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[questi, rettili, cacciano, principalmente, du...</td>\n",
       "      <td>[rettili, cacciano, principalmente, durante, g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Testo  \\\n",
       "0  [i, camaleonti, si, nutrono, principalmente, d...   \n",
       "1  [alcune, specie, più, grandi, possono, cacciar...   \n",
       "2  [la, loro, lingua, appiccicosa, e, rapida, è, ...   \n",
       "3  [le, prede, vengono, afferrate, con, un, movim...   \n",
       "4  [questi, rettili, cacciano, principalmente, du...   \n",
       "\n",
       "                                        Testo_Pulito  \n",
       "0  [camaleonti, nutrono, principalmente, insetti,...  \n",
       "1  [alcune_specie, grandi, possono, cacciare, pic...  \n",
       "2  [lingua_appiccicosa, rapida, arma, principale,...  \n",
       "3  [prede, vengono, afferrate, movimento, fulmine...  \n",
       "4  [rettili, cacciano, principalmente, durante, g...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f80b9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe8e6bea",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9cbb66",
   "metadata": {},
   "source": [
    "I questa parte andremo a trovare i migliori iperparametri e poi ad allenare il nostrom odello per ottenre una frase generata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3029d2",
   "metadata": {},
   "source": [
    "# Param Grid\n",
    "Creaiamo una funzone di supporto da poter inserire ne l nostro param-grid cambiando i parametri ogni volta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f477d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 15  # E' a lunghezza massima della frase che vogliamo generare\n",
    "### Creaiamo gli oggetti hce ci servono per allenare l'algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01fe039",
   "metadata": {},
   "outputs": [],
   "source": [
    "testo_param = data.Testo.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acb757c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(testo_param) \n",
    "sequences = tokenizer.texts_to_sequences(testo_param)  \n",
    "\n",
    "X, y = [], []  \n",
    "for sequence in sequences: \n",
    "    for i in range(1, len(sequence)):\n",
    "        X.append(sequence[:i])\n",
    "        y.append(sequence[i])\n",
    "\n",
    "X = pad_sequences(X, padding='post', maxlen=max_sequence_length - 1) \n",
    "y = np.array(y)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac4d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creazione della funzione di supporto:\n",
    "def support_function(nodi_1,dr1,nodi_2,dr2,nodi_3,dr3,active,optimize,n_batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, \n",
    "                        input_length=max_sequence_length - 1))\n",
    "    model.add(Bidirectional(LSTM(nodi_1, return_sequences=True)))\n",
    "    model.add(Dropout(dr1))\n",
    "    model.add(Bidirectional(LSTM(nodi_2, return_sequences=True)))\n",
    "    model.add(Dropout(dr2))\n",
    "    model.add(Bidirectional(LSTM(nodi_3)))\n",
    "    model.add(Dropout(dr3))\n",
    "    model.add(Dense(vocab_size, activation=active))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                        optimizer=optimize, metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X, y, epochs=50, batch_size=n_batch_size, verbose = 0)\n",
    "    \n",
    "    lista_loss = model.evaluate(X,y) ### riporta una lista col valore della loss e della metrica utilizzata (in questo caso l'accuracy)\n",
    "    \n",
    "    return lista_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a123cc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/16 [03:32<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 3s 16ms/step - loss: 5.4889 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|█████▏                                                                             | 1/16 [01:16<19:12, 76.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 4s 42ms/step - loss: 5.4889 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|██████████▎                                                                       | 2/16 [03:20<24:18, 104.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 5s 82ms/step - loss: 5.4889 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|███████████████▍                                                                  | 3/16 [07:06<34:37, 159.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 5s 103ms/step - loss: 5.4889 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|████████████████████▌                                                             | 4/16 [10:01<33:13, 166.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 5s 85ms/step - loss: 1.4370 - accuracy: 0.6662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|█████████████████████████▋                                                        | 5/16 [15:51<42:35, 232.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 5s 88ms/step - loss: 2.6077 - accuracy: 0.3589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|██████████████████████████████▊                                                   | 6/16 [18:22<34:07, 204.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 5s 110ms/step - loss: 2.0290 - accuracy: 0.4679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|███████████████████████████████████▉                                              | 7/16 [24:10<37:42, 251.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 5s 101ms/step - loss: 2.7999 - accuracy: 0.2905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████████████████████████████████████████                                         | 8/16 [27:35<31:33, 236.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 5s 101ms/step - loss: 6.2643 - accuracy: 0.0712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|██████████████████████████████████████████████▏                                   | 9/16 [32:43<30:12, 258.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 5s 112ms/step - loss: 5.4889 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████████████████████████████████████████████████▋                              | 10/16 [35:55<23:49, 238.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 6s 132ms/step - loss: 5.4889 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|███████████████████████████████████████████████████████▋                         | 11/16 [42:45<24:14, 290.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 6s 132ms/step - loss: 5.4889 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|████████████████████████████████████████████████████████████▊                    | 12/16 [46:51<18:29, 277.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 5s 112ms/step - loss: 1.5369 - accuracy: 0.5894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|█████████████████████████████████████████████████████████████████▊               | 13/16 [53:49<15:59, 319.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 6s 138ms/step - loss: 2.7113 - accuracy: 0.3184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|██████████████████████████████████████████████████████████████████████▉          | 14/16 [57:41<09:46, 293.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 5s 115ms/step - loss: 2.3615 - accuracy: 0.4050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|██████████████████████████████████████████████████████████████████████████     | 15/16 [1:04:04<05:20, 320.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 5s 112ms/step - loss: 2.9272 - accuracy: 0.2751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 16/16 [1:07:27<00:00, 285.11s/it]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m optimize \u001b[38;5;129;01min\u001b[39;00m optimizer:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n_batch_size \u001b[38;5;129;01min\u001b[39;00m batch_size:\n\u001b[1;32m---> 48\u001b[0m         cv \u001b[38;5;241m=\u001b[39m \u001b[43msupport_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43md1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn2\u001b[49m\u001b[43m,\u001b[49m\u001b[43md2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn3\u001b[49m\u001b[43m,\u001b[49m\u001b[43md3\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactive\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_batch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m         los \u001b[38;5;241m=\u001b[39m cv[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     50\u001b[0m         accur \u001b[38;5;241m=\u001b[39m cv[\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[27], line 16\u001b[0m, in \u001b[0;36msupport_function\u001b[1;34m(nodi_1, dr1, nodi_2, dr2, nodi_3, dr3, active, optimize, n_batch_size)\u001b[0m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(vocab_size, activation\u001b[38;5;241m=\u001b[39mactive))\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m                     optimizer\u001b[38;5;241m=\u001b[39moptimize, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m lista_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X,y) \u001b[38;5;66;03m### riporta una lista col valore della loss e della metrica utilizzata (in questo caso l'accuracy)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lista_loss\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Nodi per LSTM:\n",
    "nodi_1 = [80, 100]\n",
    "nodi_2 = [80, 100]\n",
    "nodi_3 = [80, 100]\n",
    "\n",
    "### drop out:\n",
    "dr1 = [0.1,0.2,0.3]\n",
    "dr2 = [0.1,0.2,0.3]\n",
    "dr3 = [0.1,0.2,0.3]\n",
    "\n",
    "### Tipologia di funzione di attivazione:\n",
    "activation = ['relu', 'softmax']\n",
    "\n",
    "### Tipologia di funzione di ottimizzazione per la funzione di perdita:\n",
    "optimizer = ['adam', 'rmsprop']\n",
    "\n",
    "### Batch size:\n",
    "batch_size= [32, 64]\n",
    "\n",
    "risultati = {\n",
    "    'nodi_1': [],\n",
    "    'dr1':[],\n",
    "    'nodi_2': [],\n",
    "    'dr2':[],\n",
    "    'nodi_3':[],\n",
    "    'dr3':[],\n",
    "    'activation' : [],\n",
    "    'optimizer' : [],\n",
    "    'batch_size' : [],\n",
    "    'loss':[],\n",
    "    'accuracy':[] \n",
    "}\n",
    "\n",
    "\n",
    "if 1 == 1:     ### Codice per far partire il tqdm\n",
    "    pbar = tqdm(total=(len(lstm_units)*len(activation)*len(optimizer)*len(epochs)*len(batch_size)))\n",
    "\n",
    "    for n1 in nodi_1:  ### 'nodi_lstm' questo assume i valori della lista\n",
    "        for d1 in dr1:\n",
    "            for n2 in nodi_2:\n",
    "                for d2 in dr2:\n",
    "                    for n3 in nodi_3:\n",
    "                        for d3 in dr3:\n",
    "                            for active in activation:\n",
    "                                for optimize in optimizer:\n",
    "                                    for n_batch_size in batch_size:\n",
    "                        \n",
    "                                        cv = support_function(n1,d1,n2,d2,n3,d3,active,optimize,n_batch_size)\n",
    "                                        los = cv[0]\n",
    "                                        accur = cv[1]\n",
    "                        \n",
    "                                        risultati['nodi_1'].append(n1)\n",
    "                                        risultati['dr1'].append(d1)\n",
    "                                        risultati['nodi_2'].append(n2)\n",
    "                                        risultati['dr2'].append(d2)\n",
    "                                        risultati['nodi_3'].append(n3)\n",
    "                                        risultati['dr3'].append(d3)\n",
    "                                        risultati['activation'].append(active)\n",
    "                                        risultati['optimizer'].append(optimize)\n",
    "                                        risultati['batch_size'].append(n_batch_size)\n",
    "\n",
    "                                        risultati['loss'].append(los)\n",
    "                                        risultati['accuracy'].append(accur)\n",
    "                    \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                                        pbar.update(1)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d674fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodi_1</th>\n",
       "      <th>dr1</th>\n",
       "      <th>nodi_2</th>\n",
       "      <th>dr2</th>\n",
       "      <th>nodi_3</th>\n",
       "      <th>dr3</th>\n",
       "      <th>activation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>32</td>\n",
       "      <td>5.488938</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>64</td>\n",
       "      <td>5.488938</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>relu</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>32</td>\n",
       "      <td>5.488938</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>relu</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>64</td>\n",
       "      <td>5.488938</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>softmax</td>\n",
       "      <td>adam</td>\n",
       "      <td>32</td>\n",
       "      <td>1.437046</td>\n",
       "      <td>0.666201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nodi_1  dr1  nodi_2  dr2  nodi_3  dr3 activation optimizer  batch_size  \\\n",
       "0      80  0.1      80  0.1      80  0.1       relu      adam          32   \n",
       "1      80  0.1      80  0.1      80  0.1       relu      adam          64   \n",
       "2      80  0.1      80  0.1      80  0.1       relu   rmsprop          32   \n",
       "3      80  0.1      80  0.1      80  0.1       relu   rmsprop          64   \n",
       "4      80  0.1      80  0.1      80  0.1    softmax      adam          32   \n",
       "\n",
       "       loss  accuracy  \n",
       "0  5.488938  0.000000  \n",
       "1  5.488938  0.000000  \n",
       "2  5.488938  0.000000  \n",
       "3  5.488938  0.000000  \n",
       "4  1.437046  0.666201  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(data = risultati)\n",
    "pd.DataFrame(df_results).to_csv('param_grid.csv', index=False)\n",
    "df_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ea146ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nodi_1              80\n",
       "dr1                0.1\n",
       "nodi_2              80\n",
       "dr2                0.1\n",
       "nodi_3              80\n",
       "dr3                0.1\n",
       "activation     softmax\n",
       "optimizer         adam\n",
       "batch_size          32\n",
       "loss          1.437046\n",
       "accuracy      0.666201\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy = df_results.sort_values(by ='accuracy' ,axis=0, ascending=False, ignore_index=True)\n",
    "best_parameters_accuracy = best_accuracy.loc[0]\n",
    "best_parameters_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5aff640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nodi_1              80\n",
       "dr1                0.1\n",
       "nodi_2              80\n",
       "dr2                0.1\n",
       "nodi_3              80\n",
       "dr3                0.1\n",
       "activation     softmax\n",
       "optimizer         adam\n",
       "batch_size          32\n",
       "loss          1.437046\n",
       "accuracy      0.666201\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss = df_results.sort_values(by ='loss' ,axis=0, ascending=True, ignore_index=True)\n",
    "best_parameters_loss = best_loss.loc[0]\n",
    "best_parameters_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ccd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bede7390",
   "metadata": {},
   "source": [
    "# Creazione LSTM\n",
    "in questa parte andreamo ad allenrare il nostro algoritmo con la migliore configurazione trovata al punto precedente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d0ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(texts, max_sequence_length):\n",
    "    tokenizer = Tokenizer()  ### è ciò che viene utilizzato per andare a tokenizzare i testi (in liste di interi)\n",
    "    tokenizer.fit_on_texts(texts)  ### questo è il comando col quale andiamo a creare le liste di interi\n",
    "    sequences = tokenizer.texts_to_sequences(texts)  ### il rigo prima allena il modello \"tokenizer\" e questo trasforma effettivamente le parole in numeri\n",
    "\n",
    "    X, y = [], []  ### vengono crate delle liste per allanere LSTM. \n",
    "    for sequence in sequences:  ### X è la lista con la quale vienve predetta Y (es. per la frase \"il sole splende\", si avranno rispettivamente X e Y: (\"Il\", \"sole\") e (\"Il\", \"sole\", \"splende\"))\n",
    "        for i in range(1, len(sequence)):\n",
    "            X.append(sequence[:i])\n",
    "            y.append(sequence[i])\n",
    "\n",
    "    X = pad_sequences(X, padding='post', maxlen=max_sequence_length - 1) ### con questo codice si allineano le sequenze di parole nelle X alla lunghezza massima da noi specificata -1\n",
    "    y = np.array(y) ### Y viene traformata in array                      ### con padding='post' tutte le sequenze che non raggiungono la lunghezza massima di almeno quella specificat da noi verranno completate con 0.\n",
    "    vocab_size = len(tokenizer.word_index) + 1             ### viene calcolato il valore del vocabolario, ovvero il totale di numeri unici (quindi di parole uniche) + 1 che sarebbe lo 0 nel caso non ci fossero abbastanza parole\n",
    "\n",
    "    return X, y, vocab_size, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ce86a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(vocab_size, max_sequence_length):\n",
    "    model = Sequential()  ### viene creato l'oggetto \"Sequential\" ovvero una rete feedforward dove l'output di uno strato viene utilizzato come input dello strato successivo\n",
    "    model.add(Embedding(vocab_size, 100, input_length=max_sequence_length - 1))  ### viene aggiunto lo strato di embedding che ha come parametri vocab_size, un intero che è la lunghezza massima degli embeddings e input_length=max_sequence_length - 1 definisce quanti nodi di input servano per iniziare (ovviamente tatni quanti la lunghezza massima di parole di una frase -1 come nel preprocess)\n",
    "    model.add(Bidirectional(LSTM(80, return_sequences=True)))  ### viene aggiunto un layer di 64 nodi di tipo LSTM ovvero un partiolare tipo di rete ricorsiva di tipo bidirezionale\n",
    "    model.add(Dropout(0.1))  # Aggiunto dropout per la regolarizzazione\n",
    "    model.add(Bidirectional(LSTM(80, return_sequences=True)))\n",
    "    model.add(Dropout(0.1))  # Aggiunto dropout per la regolarizzazione\n",
    "    model.add(Bidirectional(LSTM(80)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))  ### questo è un layere di output ovvero uno strato dove si utilizza una funzione di attivaazione per calcolare la probabiltà maggiore delle parole del vocabolario di essere l'output. questo layer è completamente connesso\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5d5f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, y, epochs, batch_size):\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size)   ### il batch è il numero di esempi di partenza che vengono presi ad ogni epoca. Piò batch si usano più l'allenamento sarà veloce, ma richiederà più memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b505d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supponendo di avere il testo delle frasi in una lista chiamata 'texts'\n",
    " # Puoi impostare la lunghezza massima della sequenza in base alle tue esigenze\n",
    "# X, y, vocab_size, tokenizer = preprocess_data(data.Testo_Pulito, max_sequence_length)\n",
    "X, y, vocab_size, tokenizer = preprocess_data(data.Testo_Pulito, max_sequence_length)\n",
    "model = build_lstm_model(vocab_size, max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "041c4af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "148/148 [==============================] - 15s 39ms/step - loss: 6.8894 - accuracy: 0.0161\n",
      "Epoch 2/100\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 6.5791 - accuracy: 0.0195\n",
      "Epoch 3/100\n",
      "148/148 [==============================] - 6s 42ms/step - loss: 6.4149 - accuracy: 0.0208\n",
      "Epoch 4/100\n",
      "148/148 [==============================] - 6s 43ms/step - loss: 6.2495 - accuracy: 0.0195\n",
      "Epoch 5/100\n",
      "148/148 [==============================] - 7s 44ms/step - loss: 6.1041 - accuracy: 0.0255\n",
      "Epoch 6/100\n",
      "148/148 [==============================] - 7s 44ms/step - loss: 5.9568 - accuracy: 0.0261\n",
      "Epoch 7/100\n",
      "148/148 [==============================] - 7s 44ms/step - loss: 5.8540 - accuracy: 0.0286\n",
      "Epoch 8/100\n",
      "148/148 [==============================] - 7s 44ms/step - loss: 5.7219 - accuracy: 0.0293\n",
      "Epoch 9/100\n",
      "148/148 [==============================] - 8s 51ms/step - loss: 5.5798 - accuracy: 0.0363\n",
      "Epoch 10/100\n",
      "148/148 [==============================] - 8s 52ms/step - loss: 5.4357 - accuracy: 0.0445\n",
      "Epoch 11/100\n",
      "148/148 [==============================] - 8s 51ms/step - loss: 5.2884 - accuracy: 0.0475\n",
      "Epoch 12/100\n",
      "148/148 [==============================] - 8s 52ms/step - loss: 5.1271 - accuracy: 0.0569\n",
      "Epoch 13/100\n",
      "148/148 [==============================] - 8s 52ms/step - loss: 4.9518 - accuracy: 0.0685\n",
      "Epoch 14/100\n",
      "148/148 [==============================] - 8s 53ms/step - loss: 4.7980 - accuracy: 0.0791\n",
      "Epoch 15/100\n",
      "148/148 [==============================] - 8s 54ms/step - loss: 4.6451 - accuracy: 0.0950\n",
      "Epoch 16/100\n",
      "148/148 [==============================] - 8s 55ms/step - loss: 4.4952 - accuracy: 0.1044\n",
      "Epoch 17/100\n",
      "148/148 [==============================] - 8s 55ms/step - loss: 4.3409 - accuracy: 0.1252\n",
      "Epoch 18/100\n",
      "148/148 [==============================] - 8s 56ms/step - loss: 4.1866 - accuracy: 0.1426\n",
      "Epoch 19/100\n",
      "148/148 [==============================] - 9s 58ms/step - loss: 4.0462 - accuracy: 0.1542\n",
      "Epoch 20/100\n",
      "148/148 [==============================] - 9s 58ms/step - loss: 3.9188 - accuracy: 0.1636\n",
      "Epoch 21/100\n",
      "148/148 [==============================] - 9s 59ms/step - loss: 3.7958 - accuracy: 0.1812\n",
      "Epoch 22/100\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 3.6419 - accuracy: 0.1996\n",
      "Epoch 23/100\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 3.5085 - accuracy: 0.2130\n",
      "Epoch 24/100\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 3.4121 - accuracy: 0.2263\n",
      "Epoch 25/100\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 3.2854 - accuracy: 0.2510\n",
      "Epoch 26/100\n",
      "148/148 [==============================] - 10s 66ms/step - loss: 3.1587 - accuracy: 0.2779\n",
      "Epoch 27/100\n",
      "148/148 [==============================] - 10s 67ms/step - loss: 3.0573 - accuracy: 0.2894\n",
      "Epoch 28/100\n",
      "148/148 [==============================] - 10s 69ms/step - loss: 2.9555 - accuracy: 0.3089\n",
      "Epoch 29/100\n",
      "148/148 [==============================] - 10s 67ms/step - loss: 2.8573 - accuracy: 0.3265\n",
      "Epoch 30/100\n",
      "148/148 [==============================] - 10s 66ms/step - loss: 2.7494 - accuracy: 0.3432\n",
      "Epoch 31/100\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 2.6638 - accuracy: 0.3611\n",
      "Epoch 32/100\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 2.5737 - accuracy: 0.3780\n",
      "Epoch 33/100\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 2.4551 - accuracy: 0.4137\n",
      "Epoch 34/100\n",
      "148/148 [==============================] - 9s 60ms/step - loss: 2.3756 - accuracy: 0.4255\n",
      "Epoch 35/100\n",
      "148/148 [==============================] - 9s 58ms/step - loss: 2.2911 - accuracy: 0.4400\n",
      "Epoch 36/100\n",
      "148/148 [==============================] - 8s 57ms/step - loss: 2.2036 - accuracy: 0.4669\n",
      "Epoch 37/100\n",
      "148/148 [==============================] - 8s 57ms/step - loss: 2.1371 - accuracy: 0.4788\n",
      "Epoch 38/100\n",
      "148/148 [==============================] - 8s 55ms/step - loss: 2.0672 - accuracy: 0.4917\n",
      "Epoch 39/100\n",
      "148/148 [==============================] - 8s 55ms/step - loss: 1.9892 - accuracy: 0.5057\n",
      "Epoch 40/100\n",
      "148/148 [==============================] - 8s 54ms/step - loss: 1.9409 - accuracy: 0.5136\n",
      "Epoch 41/100\n",
      "148/148 [==============================] - 8s 54ms/step - loss: 1.8716 - accuracy: 0.5384\n",
      "Epoch 42/100\n",
      "148/148 [==============================] - 8s 55ms/step - loss: 1.8034 - accuracy: 0.5422\n",
      "Epoch 43/100\n",
      "148/148 [==============================] - 8s 56ms/step - loss: 1.7340 - accuracy: 0.5664\n",
      "Epoch 44/100\n",
      "148/148 [==============================] - 8s 56ms/step - loss: 1.6811 - accuracy: 0.5832\n",
      "Epoch 45/100\n",
      "148/148 [==============================] - 8s 57ms/step - loss: 1.6211 - accuracy: 0.5959\n",
      "Epoch 46/100\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 1.5672 - accuracy: 0.6025\n",
      "Epoch 47/100\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 1.5249 - accuracy: 0.6135\n",
      "Epoch 48/100\n",
      "148/148 [==============================] - 9s 63ms/step - loss: 1.4745 - accuracy: 0.6232\n",
      "Epoch 49/100\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 1.4417 - accuracy: 0.6324\n",
      "Epoch 50/100\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 1.3917 - accuracy: 0.6436\n",
      "Epoch 51/100\n",
      "148/148 [==============================] - 10s 66ms/step - loss: 1.3423 - accuracy: 0.6599\n",
      "Epoch 52/100\n",
      "148/148 [==============================] - 10s 68ms/step - loss: 1.3282 - accuracy: 0.6568\n",
      "Epoch 53/100\n",
      "148/148 [==============================] - 10s 70ms/step - loss: 1.2842 - accuracy: 0.6750\n",
      "Epoch 54/100\n",
      "148/148 [==============================] - 10s 70ms/step - loss: 1.2441 - accuracy: 0.6746\n",
      "Epoch 55/100\n",
      "148/148 [==============================] - 10s 69ms/step - loss: 1.2092 - accuracy: 0.6890\n",
      "Epoch 56/100\n",
      "148/148 [==============================] - 10s 68ms/step - loss: 1.1778 - accuracy: 0.6905\n",
      "Epoch 57/100\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 1.1571 - accuracy: 0.6933\n",
      "Epoch 58/100\n",
      "148/148 [==============================] - 9s 63ms/step - loss: 1.1197 - accuracy: 0.7073\n",
      "Epoch 59/100\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 1.0874 - accuracy: 0.7164\n",
      "Epoch 60/100\n",
      "148/148 [==============================] - 9s 60ms/step - loss: 1.0722 - accuracy: 0.7179\n",
      "Epoch 61/100\n",
      "148/148 [==============================] - 9s 58ms/step - loss: 1.0282 - accuracy: 0.7259\n",
      "Epoch 62/100\n",
      "148/148 [==============================] - 8s 57ms/step - loss: 1.0069 - accuracy: 0.7304\n",
      "Epoch 63/100\n",
      "148/148 [==============================] - 8s 56ms/step - loss: 1.0105 - accuracy: 0.7268\n",
      "Epoch 64/100\n",
      "148/148 [==============================] - 8s 56ms/step - loss: 0.9751 - accuracy: 0.7344\n",
      "Epoch 65/100\n",
      "148/148 [==============================] - 8s 56ms/step - loss: 0.9530 - accuracy: 0.7378\n",
      "Epoch 66/100\n",
      "148/148 [==============================] - 9s 59ms/step - loss: 0.9136 - accuracy: 0.7558\n",
      "Epoch 67/100\n",
      "148/148 [==============================] - 8s 57ms/step - loss: 0.9059 - accuracy: 0.7499\n",
      "Epoch 68/100\n",
      "148/148 [==============================] - 9s 58ms/step - loss: 0.8715 - accuracy: 0.7588\n",
      "Epoch 69/100\n",
      "148/148 [==============================] - 9s 58ms/step - loss: 0.8629 - accuracy: 0.7603\n",
      "Epoch 70/100\n",
      "148/148 [==============================] - 9s 59ms/step - loss: 0.8558 - accuracy: 0.7647\n",
      "Epoch 71/100\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.8139 - accuracy: 0.7777\n",
      "Epoch 72/100\n",
      "148/148 [==============================] - 10s 64ms/step - loss: 0.8224 - accuracy: 0.7694\n",
      "Epoch 73/100\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 0.7901 - accuracy: 0.7779\n",
      "Epoch 74/100\n",
      "148/148 [==============================] - 10s 66ms/step - loss: 0.7893 - accuracy: 0.7779\n",
      "Epoch 75/100\n",
      "148/148 [==============================] - 10s 68ms/step - loss: 0.7796 - accuracy: 0.7777\n",
      "Epoch 76/100\n",
      "148/148 [==============================] - 10s 70ms/step - loss: 0.7590 - accuracy: 0.7813\n",
      "Epoch 77/100\n",
      "148/148 [==============================] - 10s 69ms/step - loss: 0.7427 - accuracy: 0.7879\n",
      "Epoch 78/100\n",
      "148/148 [==============================] - 10s 69ms/step - loss: 0.7252 - accuracy: 0.7894\n",
      "Epoch 79/100\n",
      "148/148 [==============================] - 10s 69ms/step - loss: 0.7396 - accuracy: 0.7896\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 10s 66ms/step - loss: 0.7192 - accuracy: 0.7889\n",
      "Epoch 81/100\n",
      "148/148 [==============================] - 9s 64ms/step - loss: 0.7167 - accuracy: 0.7921\n",
      "Epoch 82/100\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.7099 - accuracy: 0.7902\n",
      "Epoch 83/100\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.6939 - accuracy: 0.7947\n",
      "Epoch 84/100\n",
      "148/148 [==============================] - 9s 60ms/step - loss: 0.6785 - accuracy: 0.8000\n",
      "Epoch 85/100\n",
      "148/148 [==============================] - 9s 58ms/step - loss: 0.6938 - accuracy: 0.7949\n",
      "Epoch 86/100\n",
      "148/148 [==============================] - 9s 59ms/step - loss: 0.6867 - accuracy: 0.7934\n",
      "Epoch 87/100\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.6810 - accuracy: 0.7968\n",
      "Epoch 88/100\n",
      "148/148 [==============================] - 9s 58ms/step - loss: 0.6326 - accuracy: 0.8082\n",
      "Epoch 89/100\n",
      "148/148 [==============================] - 9s 59ms/step - loss: 0.6393 - accuracy: 0.8070\n",
      "Epoch 90/100\n",
      "148/148 [==============================] - 9s 60ms/step - loss: 0.6340 - accuracy: 0.8093\n",
      "Epoch 91/100\n",
      "148/148 [==============================] - 9s 61ms/step - loss: 0.6502 - accuracy: 0.8042\n",
      "Epoch 92/100\n",
      "148/148 [==============================] - 9s 62ms/step - loss: 0.6444 - accuracy: 0.8038\n",
      "Epoch 93/100\n",
      "148/148 [==============================] - 10s 65ms/step - loss: 0.6213 - accuracy: 0.8067\n",
      "Epoch 94/100\n",
      "148/148 [==============================] - 10s 66ms/step - loss: 0.6158 - accuracy: 0.8112\n",
      "Epoch 95/100\n",
      "148/148 [==============================] - 10s 68ms/step - loss: 0.6023 - accuracy: 0.8148\n",
      "Epoch 96/100\n",
      "148/148 [==============================] - 10s 69ms/step - loss: 0.6100 - accuracy: 0.8150\n",
      "Epoch 97/100\n",
      "148/148 [==============================] - 10s 70ms/step - loss: 0.6022 - accuracy: 0.8108\n",
      "Epoch 98/100\n",
      "148/148 [==============================] - 10s 69ms/step - loss: 0.6428 - accuracy: 0.8031\n",
      "Epoch 99/100\n",
      "148/148 [==============================] - 10s 70ms/step - loss: 0.6072 - accuracy: 0.8146\n",
      "Epoch 100/100\n",
      "148/148 [==============================] - 10s 68ms/step - loss: 0.5722 - accuracy: 0.8201\n"
     ]
    }
   ],
   "source": [
    "# Addestramento del modello\n",
    "epochs=100\n",
    "batch_size=32\n",
    "train_model(model, X, y, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c0f73f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modello_pre_process.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27195da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model(\"modello_tre_layer.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87bcf22",
   "metadata": {},
   "source": [
    "# Proviamo ad usare word2vec per lo strato di embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5262fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Facciamo il word embedding con word2vec\n",
    "sentences = data['Testo']\n",
    "\n",
    "# Supponendo che 'sentences' sia una lista di liste di parole\n",
    "model = Word2Vec(sentences, vector_size=100, window=10, min_count=1, sg=0) \n",
    "model.train(sentences, total_examples=len(sentences), epochs=10)\n",
    "\n",
    "\n",
    "# Estrai il vocabolario e gli embeddings dal modello Word2Vec\n",
    "vocab = model.wv.key_to_index\n",
    "word_vectors = model.wv\n",
    "\n",
    "# Dimensioni della matrice degli embeddings\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = word_vectors.vector_size\n",
    "\n",
    "# Inizializza una matrice vuota per gli embeddings\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "# Riempire la matrice con gli embeddings Word2Vec\n",
    "for word, index in vocab.items():\n",
    "    if word in word_vectors:\n",
    "        embedding_matrix[index] = word_vectors[word]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85b3a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=100, \n",
    "                            input_length=max_sequence_length - 1, weights=[embedding_matrix], trainable=False)\n",
    "\n",
    "\n",
    "def build_lstm_model2(vocab_size, max_sequence_length):\n",
    "    model = Sequential()  ### viene creato l'oggetto \"Sequential\" ovvero una rete feedforward dove l'output di uno strato viene utilizzato come input dello strato successivo\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Dropout(0.2))  # Aggiunto dropout per la regolarizzazione\n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(Dropout(0.2))  # Aggiunto dropout per la regolarizzazione\n",
    "    model.add(Dense(vocab_size, activation='softmax'))  ### questo è un layere di output ovvero uno strato dove si utilizza una funzione di attivaazione per calcolare la probabiltà maggiore delle parole del vocabolario di essere l'output. questo layer è completamente connesso\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model(model, X, y, epochs, batch_size):\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "402c9bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "16/60 [=======>......................] - ETA: 1s - loss: 7.2275 - accuracy: 0.0117"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m250\u001b[39m\n\u001b[0;32m      6\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[53], line 18\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, X, y, epochs, batch_size)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(model, X, y, epochs, batch_size):\n\u001b[1;32m---> 18\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\.conda\\NConda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, y, vocab_size, tokenizer = preprocess_data(data.Testo, max_sequence_length)\n",
    "model = build_lstm_model2(vocab_size, max_sequence_length)\n",
    "\n",
    "# Addestramento del modello\n",
    "epochs=250\n",
    "batch_size=64\n",
    "train_model(model, X, y, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894db61c",
   "metadata": {},
   "source": [
    "# Generazione della frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9ba11c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(model, tokenizer, start_words, max_sequence_length):\n",
    "    start_words = start_words.split() ### Viene suddivisa la frase in una lista di parole\n",
    "    \n",
    "    # Converti le parole di inizio in una lista di sequenze di input\n",
    "    start_sequences = tokenizer.texts_to_sequences(start_words)\n",
    "\n",
    "    # Inizializza la frase con le parole di inizio\n",
    "    sentence = start_words[:]\n",
    "\n",
    "    while True:\n",
    "        next_words = []   ### Viene iterato finchè non viene raggiunto il limite di 'max_sequence_length' oppure un punto\n",
    "\n",
    "        for start_sequence in start_sequences:\n",
    "            # Prevedi le probabilità di ogni parola nel vocabolario\n",
    "            X = pad_sequences([start_sequence], padding='post', maxlen=max_sequence_length - 1)  ### Viene creato il set di allenamento per ogni parola predetta per predirre la successiva\n",
    "            predictions = model.predict(X, verbose=0)   ### Viene predetta la parola successiva\n",
    "            next_word_index = np.argmax(predictions)    ### Viene trovato il numero (token) della parola predetta\n",
    "\n",
    "            # Converti l'indice della parola predetta in una parola reale\n",
    "            next_word = tokenizer.index_word[next_word_index]\n",
    "\n",
    "            # Aggiungi la parola predetta alla lista di parole successive\n",
    "            next_words.append(next_word)\n",
    "\n",
    "            # Aggiorna la sequenza di input con la nuova parola predetta\n",
    "            start_sequence.append(next_word_index)\n",
    "            #start_sequence = start_sequence[1:]    ### questo è uno slicing, infatti la parola [0] viene leiminata per tenere la lunghezza della lista sempre uguale.\n",
    "\n",
    "        # Aggiungi le parole predette alla frase\n",
    "        sentence.extend(next_words)\n",
    "\n",
    "        # Interrompi il ciclo se viene generato il punto o la frase ha raggiunto la lunghezza massima\n",
    "        if '.' in next_words or len(sentence) >= max_sequence_length:\n",
    "            break\n",
    "\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "611908c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parola inziale: camaleonti mangiano\n",
      "Frase generata: camaleonti mangiano abitano pazienza zone fondamentali confine successo ambienti caccia diversi caccia dimostrando camaleonti versatilità opportunità\n"
     ]
    }
   ],
   "source": [
    "# Utilizza la funzione generate_sentence per generare una frase\n",
    "start_words = input('Parola inziale: ')\n",
    "generated_sentence = generate_sentence(model, tokenizer, start_words, max_sequence_length)\n",
    "print(\"Frase generata:\", generated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea4cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
